<!DOCTYPE html>
<html lang="en">

<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
	<meta http-equiv="x-ua-compatible" content="ie=edge">
	<title>Neurally-Guided</title>
	<!-- Font Awesome -->
	<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.2/css/all.css">
	<!-- Bootstrap core CSS -->
	<link href="css/bootstrap.min.css" rel="stylesheet">
	<!-- Material Design Bootstrap -->
	<link href="css/mdb.min.css" rel="stylesheet">
	<!-- Your custom styles (optional) -->
	<link href="css/style.css" rel="stylesheet">
</head>

<body class="bg-white">

	<div class="container text-center">

		<h1 class="row py-5">Arbitrary Style Transfer Using Neurally-Guided Patch-Based Synthesis</h1>

		<div class="row pb-2">
			<div class="col-md-6">
				<div class="row pb-2 pb-md-0">
					<!-- pb-2 only on screens smaller than md -->
					<div class="col-6">
						<h5><a href="https://ondrejtexler.github.io" target="_blank" class="my-link">Ondřej Texler</a></h5>
						<p class="text-muted">CTU in Prague, FEE</p>
					</div>
					<div class="col-6">
						<h5><a href="https://dcgi.fel.cvut.cz/people/futscdav" target="_blank" class="my-link">David Futschik</a></h5>
						<p class="text-muted">CTU in Prague, FEE</p>
					</div>
				</div>
			</div>
			<div class="col-md-6">
				<div class="row">
					<div class="col-6">
						<h5><a href="https://research.adobe.com/person/jakub-fiser" target="_blank" class="my-link">Jakub Fišer</a></h5>
						<p class="text-muted">Adobe Research</p>
					</div>
					<div class="col-6">
						<h5><a href="https://research.adobe.com/person/michal-lukac" target="_blank" class="my-link">Michal Lukáč</a></h5>
						<p class="text-muted">Adobe Research</p>
					</div>
				</div>
			</div>
		</div>

		<div class="row pb-5 mx-md-5 px-md-5">
			<div class="col-md-8">
				<div class="row pb-2 pb-md-0">
					<!-- pb-2 only on screens smaller than md -->
					<div class="col">
						<h5><a href="https://research.adobe.com/person/jingwan-lu" target="_blank" class="my-link">Jingwan Lu</a></h5>
						<p class="text-muted">Adobe Research</p>
					</div>
					<div class="col">
						<h5><a href="https://research.adobe.com/person/eli-shechtman" target="_blank" class="my-link">Eli Shechtman</a></h5>
						<p class="text-muted">Adobe Research</p>
					</div>
				</div>
			</div>
			<div class="col-md-4">
				<div class="row">
					<div class="col">
						<h5><a href="https://dcgi.fel.cvut.cz/home/sykorad" target="_blank" class="my-link">Daniel Sýkora</a></h5>
						<p class="text-muted">CTU in Prague, FEE</p>
					</div>
				</div>
			</div>
		</div>

		<!--img src="img/CAG_Graphical_Abstract.jpg" class="img-fluid rounded z-depth-2" alt="Teaser">-->

		<div class="row">
			<div class="col-md-12">
				<div id="mdb-lightbox-ui"></div>
				<div class="mdb-lightbox">
					<figure>
						<a href="https://ondrejtexler.github.io/neurally_guided/img/CAG_Graphical_Abstract.jpg">
							<img src="https://ondrejtexler.github.io/neurally_guided/img/CAG_Graphical_Abstract.jpg" alt="Teaser" class="img-fluid rounded z-depth-2" />
						</a>
					</figure>
				</div>
			</div>
		</div>

		<div class="row text-muted text-justify py-5 px-3">
			<p>
				We present a new approach to example-based style transfer combining neural
				methods with patch-based synthesis to achieve compelling stylization quality
				even for high-resolution imagery. We take advantage of neural techniques to
				provide adequate stylization at the global level and use their output as a
				prior for subsequent patch-based synthesis at the detail level. Thanks to this
				combination, our method keeps the high frequencies of the original artistic
				media better, thereby dramatically increases the fidelity of the resulting
				stylized imagery. We show how to stylize extremely large images (e.g., 340 Mpix)
				without the need to run the synthesis at the pixel level, yet retaining the
				original high-frequency details.
				We demonstrate the power and generality of this approach on a novel stylization
				algorithm that delivers comparable visual quality to state-of-art neural style
				transfer while completely eschewing	any purpose-trained stylization blocks and
				only using the response of a feature extractor as guidance for patch-based synthesis.
			</p>
			<p>
				<a href="https://ondrejtexler.github.io/res/CAG_main.pdf" target="_blank" class="my-link"><i class="fas fa-file-pdf"></i> Full Text</a>
				<a href="https://ondrejtexler.github.io/res/Texler20-CAG.bib" target="_blank" class="my-link ml-4"><i class="fas fa-book"></i> BibTeX</a>

			</p>
		</div>



	</div>
	

	<!-- SCRIPTS -->
	<!-- JQuery -->
	<script type="text/javascript" src="js/jquery-3.4.1.min.js"></script>
	<!-- Bootstrap tooltips -->
	<script type="text/javascript" src="js/popper.min.js"></script>
	<!-- Bootstrap core JavaScript -->
	<script type="text/javascript" src="js/bootstrap.min.js"></script>
	<!-- MDB core JavaScript -->
	<script type="text/javascript" src="js/mdb.min.js"></script>
	<!-- My scripts-->
	<script type="text/javascript">
		// MDB Lightbox Init
		$(function () {
		 $("#mdb-lightbox-ui").load("mdb-addons/mdb-lightbox-ui.html");
		});
	</script>

</body>

</html>
